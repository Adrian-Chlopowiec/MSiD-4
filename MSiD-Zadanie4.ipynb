{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02634a56-3e69-4e50-a3c9-5de21bcac2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e444d5-4ff0-4cf5-b356-e7527f6c56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading dataset\n",
    "train_set = torchvision.datasets.FashionMNIST(root=\"data/\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2121d31f-544a-480a-af2f-30228259dd68",
   "metadata": {},
   "source": [
    "# Defining util funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a921ec2-39ad-4bc9-83de-4e18e08e0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def normalize(images):\n",
    "    return ((images / 255.) - .5) *2\n",
    "\n",
    "def load_fashionmnist(path, kind='train'):\n",
    "    labels_path = os.path.join(path,\n",
    "                              f'{kind}-labels-idx1-ubyte')\n",
    "    images_path = os.path.join(path,\n",
    "                              f'{kind}-images-idx3-ubyte')\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, n, rows, cols = struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "def plot_fashion_classes_samples(images, labels):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "    ax = ax.flatten()\n",
    "    for i in range(10):\n",
    "        img = images[labels == i][0].reshape(28, 28)\n",
    "        ax[i].imshow(img, cmap='Greys')\n",
    "        \n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_fashion_samples_5x5(images, label):\n",
    "    fig, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True)\n",
    "    ax = ax.flatten()\n",
    "    for i in range(25):\n",
    "        img = images[labels == label][i].reshape(28, 28)\n",
    "        ax[i].imshow(img, cmap='Greys')\n",
    "        \n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def classify_acc_f1(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy, f1\n",
    "\n",
    "def batch_generator(X, y, batch_size=64, shuffle=False, random_seed=None):\n",
    "    idx = np.arange(y.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        rng.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i: i + batch_size, :], y[i: i + batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958acac6-916c-4217-8ab9-e279039b416b",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d073fe0-ec20-462d-bb24-967372b6e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_fashionmnist('data/FashionMNIST/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53529c-af11-4d79-8a4b-d3635b5cf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fashion_classes_samples(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e359f-7a63-41d2-bd05-74b8389989b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fashion_samples_5x5(images, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30338dc1-2065-4ecd-9c8a-b0f18544b27a",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e62f0-3bdc-4d14-85bb-4dfe56df2e43",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a4e33c-b0aa-4e1f-9091-bda8ce34b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_fashionmnist('data/FashionMNIST/raw/')\n",
    "X_test, y_test = load_fashionmnist('data/FashionMNIST/raw/', kind='t10k')\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c050c7-4b29-4e98-b30e-15666276c15f",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93aef596-68f0-498c-836e-984e45223aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd69b38-db23-48f9-9459-cdce3de73a59",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d46e8a-1b26-4cc4-8f6f-8952288cf5c9",
   "metadata": {},
   "source": [
    "### With Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3bb58f4-4a1c-42f0-b2d5-423122a06297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8090499999999998\n",
      "{'C': 0.1, 'fit_intercept': True, 'intercept_scaling': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.1, 1.0, 10],\n",
    "              'fit_intercept': [True, False],\n",
    "              'intercept_scaling': [0.1, 1.0, 2.0]}\n",
    "\n",
    "classifier = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "gs = GridSearchCV(estimator=classifier,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train_pca, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9a9841-5ca0-41ad-9dee-ee1e0c0d4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.4287301458912836\n",
      "Accuracy: 0.438\n"
     ]
    }
   ],
   "source": [
    "lr_best = gs.best_estimator_\n",
    "accuracy, f1 = classify_acc_f1(lr_best, X_test_pca, y_test)\n",
    "print(f'F1 score: {f1}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffcf86-f09e-4f4d-a961-20595425c3ea",
   "metadata": {},
   "source": [
    "### Without Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4605c216-659a-424b-a3e1-bf817e7a66c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567333333333333\n",
      "{'C': 0.1, 'fit_intercept': False, 'intercept_scaling': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.1, 1.0, 10],\n",
    "              'fit_intercept': [True, False],\n",
    "              'intercept_scaling': [0.1, 1.0, 2.0]}\n",
    "\n",
    "classifier = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "gs = GridSearchCV(estimator=classifier,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7659c6e5-7b44-447b-a08d-d71c40f385a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8431083469320838\n",
      "Accuracy: 0.8439\n"
     ]
    }
   ],
   "source": [
    "lr_best = gs.best_estimator_\n",
    "acc, f1_ = classify_acc_f1(lr_best, X_test, y_test)\n",
    "print(f'F1 score: {f1_}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e14a87-bb18-499c-b930-63dac20053c9",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b68654-c177-40f8-97a8-40856063c036",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3152bbea-457b-4007-9b02-a7b2c9009984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_fashionmnist('data/FashionMNIST/raw/')\n",
    "X_test, y_test = load_fashionmnist('data/FashionMNIST/raw/', kind='t10k')\n",
    "\n",
    "X_train = X_train.reshape(28, 28, 60000)\n",
    "X_test = X_test.reshape(28, 28, 10000)\n",
    "\n",
    "X_train_centered = normalize(X_train)\n",
    "X_test_centered = normalize(X_test)\n",
    "\n",
    "# mean_vals = np.mean(X_train, axis=0)\n",
    "# std_val = np.std(X_train)\n",
    "# X_train_standarized = (X_train - mean_vals) / std_val\n",
    "# X_test_standarized = (X_test - mean_vals) / std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935efbe9-b45d-4e7a-b267-cac347a42fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(root=\"data/\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(root=\"data/\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c609f4-0faf-46be-ac51-71dc51ac8680",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab90d94-5bc3-41c0-bf0a-4b49982139dc",
   "metadata": {},
   "source": [
    "### Simple CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 10) no Batch Norm, no Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e497f4d6-54e7-4490-963b-ec28e6a07b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b05ce-b190-4a3a-839d-e0168429acd2",
   "metadata": {},
   "source": [
    "### CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 10) Batch Norm, no Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d762732-cdf5-4368-8afa-c2de00d952c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNNBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self._linear_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._conv_layer(x)\n",
    "        x = self._linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9e882-8229-4cba-b303-c402115999a8",
   "metadata": {},
   "source": [
    "### CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 10) Batch Norm, Dropout(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "062193df-a01e-4bfa-aba5-13e2ff923aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNNBatchNormDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self._linear_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 10),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._conv_layer(x)\n",
    "        x = self._linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb16dd-e48c-404f-9d38-d576d37bfff2",
   "metadata": {},
   "source": [
    "### CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 512) FC(512, 256) FC(256, 10) Batch Norm, no Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8cfc7233-54de-42c3-adde-c173c16cd784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNNBatchNormFC3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self._linear_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._conv_layer(x)\n",
    "        x = self._linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f41fd-73a3-4175-8684-aaaf4109adea",
   "metadata": {},
   "source": [
    "### CNN Conv(1, 64, 3) Pool(2, 2) Conv(64, 32, 3) Pool(2, 2) FC(16, 10) Batch Norm, Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ba271c9-870f-4547-ac36-0802e4aa7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNNBatchNorm2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self._linear_layer = nn.Sequential(\n",
    "            nn.Linear(800, 10),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._conv_layer(x)\n",
    "        x = self._linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a911fb2-1195-4c03-899f-a8f777a5327e",
   "metadata": {},
   "source": [
    "### CNN Vgg Like Conv(1, 16, 3, pad='same') Conv(16, 16, 3, pad='same') Pool(2) Conv(16, 32, 3) Conv(32, 32, 3) Pool(2) FC(800, 512) FC(512, 256) FC(256, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe8a64ff-b319-4de4-9f7c-9b7f12714b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNNVggLike(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            \n",
    "            nn.Conv2d(16, 16, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self._linear_layer = nn.Sequential(\n",
    "            nn.Linear(800, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._conv_layer(x)\n",
    "        x = self._linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc0510-2bca-4fda-813d-78456bf98100",
   "metadata": {},
   "source": [
    "### CNN Vgg Like Conv(1, 16, 3, pad='same') Conv(16, 16, 3, pad='same') Pool(2) Conv(16, 32, 5) Conv(32, 32, 5) Pool(2) FC(800, 512) FC(512, 256) FC(256, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0ed9b94-c92d-4815-b012-a460f0e2d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNNVggLike2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            \n",
    "            nn.Conv2d(16, 16, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 5, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 32, 5, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self._linear_layer = nn.Sequential(\n",
    "            nn.Linear(800, 800),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(800, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._conv_layer(x)\n",
    "        x = self._linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7eaa8-391e-46c7-a2c5-88f7f395179c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8569fe54-709f-4388-837b-cbcf83b2f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b67bf22-9264-4221-84a5-8ed9c1cb25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "cnn = CNNVggLike2()\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9bac6b0-94a0-4a0e-99fd-8d35e99f3447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1, 200], loss: 0.5500974816143812\n",
      "Epoch: [1, 400], loss: 0.36868770188422656\n",
      "Epoch: [1, 600], loss: 0.32034970696397763\n",
      "Epoch: [1, 800], loss: 0.3086476062410441\n",
      "Epoch: [2, 200], loss: 0.259161011957044\n",
      "Epoch: [2, 400], loss: 0.24775518353410703\n",
      "Epoch: [2, 600], loss: 0.2544451482481693\n",
      "Epoch: [2, 800], loss: 0.23874065437209066\n",
      "Epoch: [3, 200], loss: 0.20298004468631506\n",
      "Epoch: [3, 400], loss: 0.20381918107744437\n",
      "Epoch: [3, 600], loss: 0.20931758978708306\n",
      "Epoch: [3, 800], loss: 0.21406435436714236\n",
      "Epoch: [4, 200], loss: 0.16864517785084607\n",
      "Epoch: [4, 400], loss: 0.17707917015606434\n",
      "Epoch: [4, 600], loss: 0.18489056031907622\n",
      "Epoch: [4, 800], loss: 0.17887498951287725\n",
      "Epoch: [5, 200], loss: 0.14686024627980576\n",
      "Epoch: [5, 400], loss: 0.14442190857388865\n",
      "Epoch: [5, 600], loss: 0.15751738087671935\n",
      "Epoch: [5, 800], loss: 0.15232041363964727\n",
      "Epoch: [6, 200], loss: 0.12163447127232899\n",
      "Epoch: [6, 400], loss: 0.12510268421066767\n",
      "Epoch: [6, 600], loss: 0.1446788756073869\n",
      "Epoch: [6, 800], loss: 0.14014671469603351\n",
      "Epoch: [7, 200], loss: 0.1065479681859888\n",
      "Epoch: [7, 400], loss: 0.11581658794727158\n",
      "Epoch: [7, 600], loss: 0.11868077827308646\n",
      "Epoch: [7, 800], loss: 0.12263410980228204\n",
      "Epoch: [8, 200], loss: 0.08037277400942903\n",
      "Epoch: [8, 400], loss: 0.09356639705757475\n",
      "Epoch: [8, 600], loss: 0.09599780480859417\n",
      "Epoch: [8, 800], loss: 0.10370704132932515\n",
      "Epoch: [9, 200], loss: 0.07701231260086648\n",
      "Epoch: [9, 400], loss: 0.08445910159872855\n",
      "Epoch: [9, 600], loss: 0.09030424103365471\n",
      "Epoch: [9, 800], loss: 0.08326535567468098\n",
      "Epoch: [10, 200], loss: 0.06140065427527917\n",
      "Epoch: [10, 400], loss: 0.06438070947500929\n",
      "Epoch: [10, 600], loss: 0.061678693941022135\n",
      "Epoch: [10, 800], loss: 0.08433789473925553\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f'Epoch: [{epoch + 1}, {i + 1}], loss: {running_loss / 199}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99cbf94-305d-4db1-8296-30fdb9c09578",
   "metadata": {},
   "source": [
    "torch.save(cnn.state_dict(), 'models/vgg_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952c40a-7a58-4ef8-9c3f-f6053b0fd3b3",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e6ac2-a31b-48fb-a99c-bf4f9dc3ad01",
   "metadata": {},
   "source": [
    "cnn = CNNBatchNorm()\n",
    "cnn.load_state_dict(torch.load('models/batch_norm_cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c900189-5f39-41c3-8614-0a0f35764afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9203\n",
      "F1-Score: 0.9196067290354151\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        y_test.extend(labels)\n",
    "        \n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        y_pred.extend(Tensor.cpu(predicted))\n",
    "        \n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212caf0c-59c9-4be8-a080-40768991c18f",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1b85e-4336-4dbf-85e5-6a69f78584d3",
   "metadata": {},
   "source": [
    "##### LogisticRegression:\n",
    "Accuracy: 84.39%<br>\n",
    "F1-Score: 84.31%<br>\n",
    "\n",
    "##### Simple CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 10) no Batch Norm, no Dropout:\n",
    "Accuracy: 87.75%<br>\n",
    "F1-Score: 87.72%<br>\n",
    "\n",
    "##### CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 10) Batch Norm, no Dropout:\n",
    "Accuracy: 90.07%<br>\n",
    "F1-Score: 90.13%<br>\n",
    "\n",
    "##### CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 10) Batch Norm, Dropout(0.3):\n",
    "Accuracy: 72.13%<br>\n",
    "F1-Score: 72.73%<br>\n",
    "\n",
    "##### CNN Conv(1, 32, 5) Pool(2, 2) Conv(32, 64, 5) Pool(2, 2) FC(1024, 512) FC(512, 256) FC(256, 10) Batch Norm, no Dropout:\n",
    "Accuracy: 90.69%<br>\n",
    "F1-Score: 90.67%<br>\n",
    "\n",
    "##### CNN Conv(1, 64, 3) Pool(2, 2) Conv(64, 32, 3) Pool(2, 2) FC(16, 10) Batch Norm, no Dropout:\n",
    "Accuracy: 89.83%<br>\n",
    "F1-Score: 89.91%<br>\n",
    "\n",
    "##### CNN Conv(1, 64, 3) Pool(2, 2) Conv(64, 32, 3) Pool(2, 2) FC(16, 10) Batch Norm, Dropout:\n",
    "Accuracy: 86.61%<br>\n",
    "F1-Score: 86.61%<br>\n",
    "\n",
    "##### CNN Vgg Like Conv(1, 16, 3, pad='same') Conv(16, 16, 3, pad='same') Pool(2) Conv(16, 32, 3) Conv(32, 32, 3) Pool(2) FC(800, 512) FC(512, 256) FC(256, 10)\n",
    "Accuracy: 92.20%<br>\n",
    "F1-Score: 92.12%<br>\n",
    "\n",
    "##### CNN Vgg Like Conv(1, 16, 3, pad='same') Conv(16, 16, 3, pad='same') Pool(2) Conv(16, 32, 5, pad=(1, 1)) Conv(32, 32, 5, pad=(1, 1)) Pool(2) FC(800, 512) FC(512, 256) FC(256, 10)\n",
    "Accuracy: 92.62%<br>\n",
    "F1-Score: 92.61%<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b39fb-e93b-4eec-b27f-c9e4d4ad151f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
